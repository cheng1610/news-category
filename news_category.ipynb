{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cheng1610/news-category/blob/main/news_category.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gUj8a4dkVYZ"
      },
      "source": [
        "# 基於深度學習的新聞主題自動分類系統\n",
        "### 1. 專案介紹&簡介\n",
        "- 本專案開發一個自動判斷新聞主題的系統，可以將新聞進行多分類，例如：\n",
        "  - World：國際新聞\n",
        "  - Sports：體育新聞\n",
        "  - Business：商業與經濟新聞\n",
        "  - Sci/Tech：科技與科學新聞\n",
        "- **開發環境**：Google Colab\n",
        "- **深度學習框架**：TensorFlow\n",
        "- **資料集**：使用包含在TensorFlow Datasets中的AG News Dataset (一個經典的英文新聞分類資料集，常用於自然語言處理和文本分類的研究與測試)\n",
        "- **資料量**：訓練集共120,000篇文章，測試集共7,600 篇文章\n",
        "- **資料結構**：訓練集以及測試集的每筆資料(文章)包含兩個部分\n",
        "   - text：新聞文字，型態為 TensorFlow Tensor (dtype=tf.string)\n",
        "   - label(標籤)：對應新聞類別，標籤為整數 0~3，依序對應 World、Sports、Business、Sci/Tech，型態為 TensorFlow Tensor (dtype=tf.int64)\n",
        "### 2. 架構\n",
        "1. **資料預處理**  \n",
        "   - 使用Tokenizer將文字轉成數字序列\n",
        "   - 用Embeddings層轉換為向量形式\n",
        "   - 使用 pad_sequences 將序列長度統一\n",
        "2. **模型訓練**  \n",
        "   - 使用Embeding, LSTM, Dense模型進行文本分類  \n",
        "   - 設定損失函數與優化器，訓練模型\n",
        "3. **模型評估**  \n",
        "   - 使用準確率與精確率進行評估\n",
        "     \n",
        "### 3. 預期成果\n",
        "- 模型能對新聞文本自動分類並且達到高準確率\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "t-3wRRROps23"
      },
      "outputs": [],
      "source": [
        "#載入相關套件\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "LT2_V55IzqLm"
      },
      "outputs": [],
      "source": [
        "#下載AG news資料集，並且分割成訓練集以及測試集\n",
        "dataset = tfds.load(\n",
        "    \"ag_news_subset\",\n",
        "    as_supervised=True\n",
        ")\n",
        "\n",
        "train_ds = dataset['train']\n",
        "test_ds = dataset['test']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "GL3gAKh3qLRm"
      },
      "outputs": [],
      "source": [
        "#將TensorFlow裡的Dataset物件格式的新聞資料轉換為Python list，為後續Tokenizer做使用\n",
        "\n",
        "#訓練資料\n",
        "train_texts = []  #train_texts =  [新聞文字，新聞文字，.....，新聞文字]\n",
        "train_labels = [] #train_labels = [標籤，標籤，.....，標籤]\n",
        "\n",
        "for text, label in train_ds:\n",
        "    train_texts.append(text.numpy().decode('utf-8')) #將原本以tensor物件儲存的文字內容解碼為字串格式\n",
        "    train_labels.append(label.numpy())\n",
        "\n",
        "#測試資料\n",
        "test_texts = []   #test_texts =  [新聞文字，新聞文字，.....，新聞文字]\n",
        "test_labels = []  #test_labels = [標籤，標籤，.....，標籤]\n",
        "\n",
        "for text, label in test_ds:\n",
        "    test_texts.append(text.numpy().decode('utf-8'))  #將原本以tensor物件儲存的文字內容解碼為字串格式\n",
        "    test_labels.append(label.numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "pLyRyhZxqPhD"
      },
      "outputs": [],
      "source": [
        "#將文字資料透過Tokenizer轉換為模型可接受的數值序列\n",
        "\n",
        "vocab_size = 10000  # 詞彙量上限\n",
        "max_len = 200       # 最大序列長度\n",
        "\n",
        "#設置Tokenizer，將訓練集裡最多出現次數的詞彙依序編號，最多到10000(vocab_size),超過10000的以<OOV>表示\n",
        "tokenizer = Tokenizer(num_words=vocab_size, oov_token=\"<OOV>\")\n",
        "#將訓練集放置在Tokenizer裡面建立詞彙索引\n",
        "tokenizer.fit_on_texts(train_texts)\n",
        "\n",
        "#將文字轉換為數值序列\n",
        "#例子: \"Apple releases new iPhone...\" --> [1, 2, 3, 4,...]\n",
        "X_train = tokenizer.texts_to_sequences(train_texts)\n",
        "X_test = tokenizer.texts_to_sequences(test_texts)\n",
        "\n",
        "#透過pad_sequences將所有輸入資料的長度(序列長度)一致(max_len = 200)，不足往前補0\n",
        "#例子:\n",
        "#   原始序列1: [5, 2, 1, ...](假設長度 100)\n",
        "#       pad_sequences 後: [0, 0, ...0, 5, 2, 1,...] (長度 200)\n",
        "#   原始序列2: [7, 3, 8, 2, 9, 4, ...] (假設長度 250)\n",
        "#       pad_sequences 後: [7, 3, 8, 2, 9, 4, ...] (只保留前 200 個元素)\n",
        "x_train = pad_sequences(X_train, maxlen=max_len, padding='pre', truncating='post')\n",
        "x_test = pad_sequences(X_test, maxlen=max_len, padding='pre', truncating='post')\n",
        "\n",
        "# 標籤轉成 numpy array，方便做運算\n",
        "y_train = np.array(train_labels)\n",
        "y_test = np.array(test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "id": "XmyNKfnKqSPU",
        "outputId": "3ef5df8a-a29f-4e4d-cef6-675f9eada1c0",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_3 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#設置模型，用於新聞主題分類\n",
        "embedding_dim = 64 #Embedding 層的維度，每個詞彙將被表示為 64 維向量\n",
        "#例子:\n",
        "#假設一段文字有'Apple'這個詞彙，經 Embedding 層轉換後會得到一個 64 維向量表示，例如：\n",
        "#'Apple' -> [0.12, -0.03, 0.45, ..., 0.08]  # 共 64 個數字(列表長度為64)\n",
        "#同理，每個詞都會被映射成一個向量，向量中包含詞的語意資訊\n",
        "\n",
        "#使用Sequential來串接神經網路模型\n",
        "#第一層神經網路Embedding層將文字向量化\n",
        "#第二層神經網路LSTM長短期記憶層，用於捕捉序列中詞語的上下文語意\n",
        "#第三層神經網路Dense全連接層，32 個神經元將 LSTM 輸出的語意特徵進行線性組合並加上非線性激活（ReLU），提取更高階的特徵表示。\n",
        "#第四層神經網路Dense全連接層，4 個神經元對應將特徵映射到 4 類新聞，使用 softmax 激活函數輸出各類別機率，模型最終根據最大機率決定新聞分類\n",
        "model = Sequential([\n",
        "    Embedding(vocab_size, embedding_dim, input_length=max_len),\n",
        "    LSTM(64, return_sequences=False),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(4, activation='softmax')  # 4 類新聞\n",
        "])\n",
        "\n",
        "#編譯模型，設定損失函數、優化器與評估指標\n",
        "#損失函數用於多分類問題，當標籤是整數形式（0~3）時使用 sparse_categorical_crossentropy\n",
        "#優化器Adam是一種自適應學習率的梯度下降方法，收斂快且穩定\n",
        "#訓練與測試時會計算準確率 (accuracy) 作為模型性能參考\n",
        "model.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "#輸出模型的完整架構\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "YyaB-4CsqTDd"
      },
      "outputs": [],
      "source": [
        "#為了避免避免模型學到「順序」而不是「內容」，因此需要使用shuffle隨機打亂資料順序，所以需要先將文字序列與標籤轉換成TensorFlow Dataset以便操作\n",
        "batch_size = 64 #將資料分成每批64筆進行訓練或測試，總共需要1875批(資料大小為120000筆，因此120000/64=1875)\n",
        "\n",
        "#把X_train和y_train變回TensorFlow Dataset 物件\n",
        "train_ds_tf = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "#自動在內部為你建立一個大小為10000筆資料的緩衝區(由於資料過大因此需要緩衝區來減少記憶體)，用來隨機抽資料(每批64筆資料)\n",
        "train_ds_tf = train_ds_tf.shuffle(10000).batch(batch_size)\n",
        "\n",
        "#把X_test和y_test變回TensorFlow Dataset 物件\n",
        "test_ds_tf = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
        "test_ds_tf = test_ds_tf.batch(batch_size)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MM3NHBiSqWKH",
        "outputId": "d03599e9-ef32-4d70-b157-fd7508514df1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - accuracy: 0.7546 - loss: 0.6025 - val_accuracy: 0.9030 - val_loss: 0.2910\n",
            "Epoch 2/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 11ms/step - accuracy: 0.9128 - loss: 0.2564 - val_accuracy: 0.9012 - val_loss: 0.2882\n",
            "Epoch 3/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.9280 - loss: 0.2078 - val_accuracy: 0.9063 - val_loss: 0.2906\n",
            "Epoch 4/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.9398 - loss: 0.1730 - val_accuracy: 0.9014 - val_loss: 0.3139\n",
            "Epoch 5/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.9495 - loss: 0.1413 - val_accuracy: 0.9028 - val_loss: 0.3603\n"
          ]
        }
      ],
      "source": [
        "#負責訓練模型並記錄訓練歷史\n",
        "epochs = 5 #表示整個訓練資料將被模型完整看 5 遍\n",
        "\n",
        "# 訓練模型並記錄訓練過程\n",
        "history = model.fit(\n",
        "    train_ds_tf, #訓練資料（已經 shuffle + batch）\n",
        "    validation_data=test_ds_tf,# 驗證資料，用於每個 epoch 後評估模型準確率\n",
        "    epochs=epochs# 訓練的總輪數\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFbxikaTpFGc"
      },
      "source": [
        "# 模型實測\n",
        "使用python套件newspaper3k抓取BBC新聞內容放進模型裡進行分類\n",
        "## 使用新聞內容\n",
        "### 1.體育新聞\n",
        "- 網址: https://www.bbc.com/sport/basketball/articles/c8dyzyj9d88o\n",
        "\n",
        "### 2.科學新聞\n",
        "- 網址: https://www.bbc.com/news/articles/cd6xl3ql3v0o\n",
        "\n",
        "### 3.金融新聞\n",
        "- 網址: https://www.bbc.com/news/articles/cd74lyr094vo\n",
        "\n",
        "### 4.科學新聞\n",
        "- 網址: https://www.bbc.com/future/article/20251023-how-hydrofoil-boats-could-cut-emissions-from-water-transport\n",
        "\n",
        "### 5.世界新聞\n",
        "- 網址: https://www.bbc.com/culture/article/20251223-the-salt-path-and-2025s-most-scandalous-books\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sduIPUlVdfIX",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!pip install newspaper3k\n",
        "!pip install lxml[html_clean]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5T-Jx1sud2qI",
        "outputId": "05b6e080-7ea9-4ee3-c078-64e1d5f5c98a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------text1------------------------------------\n",
            " Nikola Jokic recorded a 56-point triple-double and broke a record set by Steph Curry as the Denver Nuggets beat the Minnesota Timberwolves 142-138 on Christmas Day.\n",
            "\n",
            "The Serb hit 56 points, recorded 16 rebounds and 15 assists - becoming the first player in NBA history to hit at least 55 points, 15 rebounds and 15 assists in a triple-double.\n",
            "\n",
            "Three-time MVP Jokic hit 18 of his 56 points in overtime, breaking Curry's record of 17 overtime points from 2016.\n",
            "\n",
            "The Timberwolves took the game in Denver to overtime after clawing back a 15-point deficit in the final five minutes of the game.\n",
            "\n",
            "Anthony Edwards top-scored for the Timberwolves with 44 points, including the game-tying three that took the game to overtime.\n",
            "\n",
            "But the 24-year-old was ejected in the extra period for arguing over foul calls as the Nuggets claimed the win.\n",
            "\n",
            "The Nuggets are third in the Western Conference, with the Timberwolves in fifth.\n",
            "\n",
            "------------------------------------text2------------------------------------\n",
            " One in three using AI for emotional support and conversation, UK says\n",
            "\n",
            "18 December 2025 Share Save Chris Vallance Senior technology reporter Share Save\n",
            "\n",
            "Getty Images\n",
            "\n",
            "One in three adults in the UK are using artificial intelligence (AI) for emotional support or social interaction, according to research published by a government body. And one in 25 people turned to the tech for support or conversation every day, the AI Security Institute (AISI) said in its first report. The report is based on two years of testing the abilities of more than 30 unnamed advanced AIs - covering areas critical to security, including cyber skills, chemistry and biology. The government said AISI's work would support its future plans by helping companies fix problems \"before their AI systems are widely used\".\n",
            "\n",
            "A survey by AISI of over 2,000 UK adults found people were primarily using chatbots like ChatGPT for emotional support or social interaction, followed by voice assistants like Amazon's Alexa. Researchers also analysed what happened to an online community of more than two million Reddit users dedicated to discussing AI companions, when the tech failed. The researchers found when the chatbots went down, people reported self-described \"symptoms of withdrawal\", such as feeling anxious or depressed - as well as having disrupted sleep or neglecting their responsibilities.\n",
            "\n",
            "Doubling cyber skills\n",
            "\n",
            "As well as the emotional impact of AI use, AISI researchers looked at other risks caused by the tech's accelerating capabilities. There is considerable concern about AI enabling cyber attacks, but equally it can be used to help secure systems from hackers. Its ability to spot and exploit security flaws was in some cases \"doubling every eight months\", the report suggests. And AI systems were also beginning to complete expert-level cyber tasks which would typically require over 10 years of experience. Researchers also found the tech's impact in science was also growing rapidly. In 2025, AI models had \"long since exceeded human biology experts with PhDs - with performance in chemistry quickly catching up\".\n",
            "\n",
            "'Humans losing control'\n",
            "\n",
            "From novels such as Isaac Asimov's I, Robot to modern video games like Horizon: Zero Dawn, sci-fi has long imagined what would happen if AI broke free of human control. Now, according to the report, the \"worst-case scenario\" of humans losing control of advanced AI systems is \"taken seriously by many experts\". AI models are increasingly exhibiting some of the capabilities required to self-replicate across the internet, controlled lab tests suggested. AISI examined whether models could carry out simple versions of tasks needed in the early stages of self-replication - such as \"passing know-your customer checks required to access financial services\" in order to successfully purchase the computing on which their copies would run. But the research found to be able to do this in the real world, AI systems would need to complete several such actions in sequence \"while remaining undetected\", something its research suggests they currently lack the capacity to do. Institute experts also looked at the possibility of models \"sandbagging\" - or strategically hiding their true capabilities from testers. They found tests showed it was possible, but there was no evidence of this type of subterfuge taking place. In May, AI firm Anthropic released a controversial report which described how an AI model was capable of seemingly blackmail-like behaviour if it thought its \"self-preservation\" was threatened. The threat from rogue AI is, however, a source of profound disagreement among leading researchers - many of whom feel it is exaggerated.\n",
            "\n",
            "'Universal jailbreaks'\n",
            "\n",
            "------------------------------------text3------------------------------------\n",
            " US pauses offshore wind projects over security concerns\n",
            "\n",
            "Dominion Energy's offshore project in Virginia is among those paused under the Department of Interior's new order.\n",
            "\n",
            "Renewable energy companies, as well as state leaders, have expressed alarm over the administration's stance.\n",
            "\n",
            "President Donald Trump has long opposed wind energy, saying it is unreliable and drives up costs, and attempted to stop all projects when he returned to office. Interior Secretary Doug Burgum has said wind farms have no future in the US energy grid.\n",
            "\n",
            "In a statement, the Department of the Interior said it was pausing five large-sale projects to look into how windmills could interfere with radar and create other risks to east coast cities.\n",
            "\n",
            "The US is immediately pausing leases for offshore wind energy projects currently being built near the Atlantic coastline, citing security concerns.\n",
            "\n",
            "In its statement, the Department of the Interior said the pause \"addresses emerging national security risks, including the rapid evolution of the relevant adversary technologies, and the vulnerabilities created by large-scale offshore wind projects with proximity near our east coast population centres\".\n",
            "\n",
            "The five wind farms now on pause are being constructed off the coast of New York, Virginia, Massachusetts, Rhode Island, and Connecticut.\n",
            "\n",
            "Specifically, the announcement noted that officials are concerned about radar interference \"clutter\" that can obscure real moving targets or, conversely, create false ones. It added that a radar's threshold for false-alarm detection could be increased to reduce some clutter, but only at the risk of missing actual targets.\n",
            "\n",
            "The wind projects could make it difficult to \"determine what's friend and foe in our airspace\", Burgum said in an interview with Fox Business on Monday, where he cited drone strikes between Russia and Ukraine and between Iran and Israel as examples.\n",
            "\n",
            "Dominion Energy, the company behind the Virginia wind farm, said its project is far offshore and \"does not raise visual impact concerns.\"\n",
            "\n",
            "\"The project's two pilot turbines have been operating for five years without causing any impacts to national security,\" it said in a statement.\n",
            "\n",
            "Dominion saw its share price drop more than 3% after the announcement.\n",
            "\n",
            "Orsted, the Danish wind energy giant, recorded a 12% drop in its share price, while turbine maker Vestas' stock fell by 2.6%.\n",
            "\n",
            "Connecticut Governor Ned Lamont, a Democrat, described the pause as an \"erratic\" move that \"will drive up the price of electricity in Connecticut and throughout the region\".\n",
            "\n",
            "\"This project is nearing completion and providing good-paying clean energy jobs,\" he added. \"Businesses and residents deserve economic predictability, yet with the administration's constant starts and stops they're left with the opposite.\"\n",
            "\n",
            "Earlier in December, a federal judge struck down an attempt by President Trump to ban new wind power projects in the US, calling it \"arbitrary and capricious and contrary to law\".\n",
            "\n",
            "On the first day of his administration in January, Trump issued a memorandum halting permits and new leases until a federal review could be undertaken.\n",
            "\n",
            "Five months later, 17 US states led by New York sued the administration, calling the ban an \"existential\" threat to the US wind industry.\n",
            "\n",
            "Demand in the US for energy is expected to significantly expand in the years ahead, driven by the needs of artificial intelligence firms.\n",
            "\n",
            "Last week, Trump Media, the parent company of Truth Social that is majority-owned by the president, said it was getting into the energy business, announcing a merger with a fusion firm TAE Technologies.\n",
            "\n",
            "------------------------------------text4------------------------------------\n",
            " US pauses offshore wind projects over security concerns\n",
            "\n",
            "Dominion Energy's offshore project in Virginia is among those paused under the Department of Interior's new order.\n",
            "\n",
            "Renewable energy companies, as well as state leaders, have expressed alarm over the administration's stance.\n",
            "\n",
            "President Donald Trump has long opposed wind energy, saying it is unreliable and drives up costs, and attempted to stop all projects when he returned to office. Interior Secretary Doug Burgum has said wind farms have no future in the US energy grid.\n",
            "\n",
            "In a statement, the Department of the Interior said it was pausing five large-sale projects to look into how windmills could interfere with radar and create other risks to east coast cities.\n",
            "\n",
            "The US is immediately pausing leases for offshore wind energy projects currently being built near the Atlantic coastline, citing security concerns.\n",
            "\n",
            "In its statement, the Department of the Interior said the pause \"addresses emerging national security risks, including the rapid evolution of the relevant adversary technologies, and the vulnerabilities created by large-scale offshore wind projects with proximity near our east coast population centres\".\n",
            "\n",
            "The five wind farms now on pause are being constructed off the coast of New York, Virginia, Massachusetts, Rhode Island, and Connecticut.\n",
            "\n",
            "Specifically, the announcement noted that officials are concerned about radar interference \"clutter\" that can obscure real moving targets or, conversely, create false ones. It added that a radar's threshold for false-alarm detection could be increased to reduce some clutter, but only at the risk of missing actual targets.\n",
            "\n",
            "The wind projects could make it difficult to \"determine what's friend and foe in our airspace\", Burgum said in an interview with Fox Business on Monday, where he cited drone strikes between Russia and Ukraine and between Iran and Israel as examples.\n",
            "\n",
            "Dominion Energy, the company behind the Virginia wind farm, said its project is far offshore and \"does not raise visual impact concerns.\"\n",
            "\n",
            "\"The project's two pilot turbines have been operating for five years without causing any impacts to national security,\" it said in a statement.\n",
            "\n",
            "Dominion saw its share price drop more than 3% after the announcement.\n",
            "\n",
            "Orsted, the Danish wind energy giant, recorded a 12% drop in its share price, while turbine maker Vestas' stock fell by 2.6%.\n",
            "\n",
            "Connecticut Governor Ned Lamont, a Democrat, described the pause as an \"erratic\" move that \"will drive up the price of electricity in Connecticut and throughout the region\".\n",
            "\n",
            "\"This project is nearing completion and providing good-paying clean energy jobs,\" he added. \"Businesses and residents deserve economic predictability, yet with the administration's constant starts and stops they're left with the opposite.\"\n",
            "\n",
            "Earlier in December, a federal judge struck down an attempt by President Trump to ban new wind power projects in the US, calling it \"arbitrary and capricious and contrary to law\".\n",
            "\n",
            "On the first day of his administration in January, Trump issued a memorandum halting permits and new leases until a federal review could be undertaken.\n",
            "\n",
            "Five months later, 17 US states led by New York sued the administration, calling the ban an \"existential\" threat to the US wind industry.\n",
            "\n",
            "Demand in the US for energy is expected to significantly expand in the years ahead, driven by the needs of artificial intelligence firms.\n",
            "\n",
            "Last week, Trump Media, the parent company of Truth Social that is majority-owned by the president, said it was getting into the energy business, announcing a merger with a fusion firm TAE Technologies.\n",
            "\n",
            "------------------------------------text5------------------------------------\n",
            " In 2025, personal stories proved popular and powerful – but several controversies raised questions about the future of the memoir genre.\n",
            "\n",
            "Personal stories can be powerful, and no more so than in 2025. Over the past 12 months, memoirs have frequently made the headlines both for the stories they told – and the details they missed out.\n",
            "\n",
            "In the spring, Sarah Wynn-Williams's Careless People, an exposé of her time working as an executive at Meta, the company behind Facebook and Instagram, became a bestseller despite a gagging order banning her from publicising it.\n",
            "\n",
            "Later in the year, Virginia Giuffre's powerful posthumous autobiography Nobody's Girl detailed her sexual abuse at the hands of Jeffrey Epstein and his circle, including allegations against Andrew Mountbatten-Windsor, which he has always denied. The book – which sold one million copies in two months – intensified pressure for the former prince to be stripped of his titles – which he was in late October.\n",
            "\n",
            "Kamala Harris's 107 days, an account of her doomed presidential run, garnered plenty of column inches for her criticism of Joe Biden. And the year also saw high-profile memoirs by Margaret Atwood, Malala Yousafzai and Jacinda Ardern, as well as moving life stories like Arundhati Roy's Mother Mary Comes to Me and Yiyun Li's Things in Nature Merely Grow, an account of losing two sons to suicide.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#抓取新聞文章\n",
        "from newspaper import Article\n",
        "\n",
        "news = []\n",
        "titles = []\n",
        "\n",
        "#體育新聞\n",
        "url = 'https://www.bbc.com/sport/basketball/articles/c8dyzyj9d88o'\n",
        "article = Article(url)\n",
        "article.download()\n",
        "article.parse()\n",
        "text1 = article.text  # 內文\n",
        "news.append(text1)\n",
        "titles.append(article.title)\n",
        "print(\"------------------------------------text1------------------------------------\\n\", text1)\n",
        "print()\n",
        "\n",
        "#科技新聞\n",
        "url = 'https://www.bbc.com/news/articles/cd6xl3ql3v0o'\n",
        "article = Article(url)\n",
        "article.download()\n",
        "article.parse()\n",
        "text2 = article.text  # 內文\n",
        "news.append(text2)\n",
        "titles.append(article.title)\n",
        "print(\"------------------------------------text2------------------------------------\\n\", text2)\n",
        "print()\n",
        "\n",
        "#金融新聞\n",
        "url = 'https://www.bbc.com/news/articles/cd74lyr094vo'\n",
        "article = Article(url)\n",
        "article.download()\n",
        "article.parse()\n",
        "text3 = article.text  # 內文\n",
        "news.append(text3)\n",
        "titles.append(article.title)\n",
        "print(\"------------------------------------text3------------------------------------\\n\", text3)\n",
        "print()\n",
        "\n",
        "#科學新聞\n",
        "url = 'https://www.bbc.com/future/article/20251023-how-hydrofoil-boats-could-cut-emissions-from-water-transport'\n",
        "article = Article(url)\n",
        "article.download()\n",
        "article.parse()\n",
        "text4 = article.text  # 內文\n",
        "news.append(text4)\n",
        "titles.append(article.title)\n",
        "print(\"------------------------------------text4------------------------------------\\n\", text3)\n",
        "print()\n",
        "\n",
        "#世界新聞(文化)\n",
        "url = 'https://www.bbc.com/culture/article/20251223-the-salt-path-and-2025s-most-scandalous-books'\n",
        "article = Article(url)\n",
        "article.download()\n",
        "article.parse()\n",
        "text5 = article.text  # 內文\n",
        "news.append(text5)\n",
        "titles.append(article.title)\n",
        "print(\"------------------------------------text5------------------------------------\\n\", text5)\n",
        "print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fFooTgMrqXp-",
        "outputId": "4d761eaf-6962-45ed-cd38-f870605428cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "新聞: Nikola Jokic breaks Steph Curry record with historic triple-double in Denver Nuggets win\n",
            "預測主題: Sports\n",
            "\n",
            "新聞: One in three using AI for emotional support and conversation, UK says\n",
            "預測主題: Sci/Tech\n",
            "\n",
            "新聞: US pauses offshore wind projects over national security concerns\n",
            "預測主題: Business\n",
            "\n",
            "新聞: 'The sound completely changes': To electrify boats, make them fly\n",
            "預測主題: Sci/Tech\n",
            "\n",
            "新聞: The Salt Path and 2025's most scandalous books\n",
            "預測主題: World\n",
            "\n"
          ]
        }
      ],
      "source": [
        "seq = tokenizer.texts_to_sequences(news)\n",
        "padded = pad_sequences(seq, maxlen=max_len, padding='post')\n",
        "\n",
        "#放進模型做分類\n",
        "pred = model.predict(padded)\n",
        "labels = ['World', 'Sports', 'Business', 'Sci/Tech']\n",
        "\n",
        "# print(pred)\n",
        "\n",
        "#輸出分類結果\n",
        "for title, p in zip(titles, pred):\n",
        "    pred_class = labels[np.argmax(p)]\n",
        "    print(f\"新聞: {title}\")\n",
        "    print(f\"預測主題: {pred_class}\\n\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPED484DxmQJ8kJv9j3436I",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}